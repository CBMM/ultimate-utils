checking installations for conda: https://stackoverflow.com/questions/59903548/how-does-one-check-if-conda-develop-installed-my-project-packages/59903590#59903590
python -c "import sys; [print(p) for p in sys.path]"
conda develop -u .

conda create -n automl-meta-learning python=3.7
conda activate automl-meta-learning
conda env list
conda remove --name automl-meta-learning --all

python -m cProfile -s cumtime meta_learning_experiments_submission.py > profile.txt

pip install --no-deps torchmeta

----
Vision cluster

K40s ?
GeForce GRX Titan X ?
Titan X (Pascal): CNN 0.542 Transformer: 0.75
Titan Xp: CNN: 0.584 Transformer: 0.876
Quadron RTX 6000: CNN 1.084 Transformer: 1.084

ssh miranda9@vision-sched.cs.illinois.edu

condor_submit -i
condor_submit -i interactive.sub
condor_submit -i request_cpus=8 request_gpus=1
### condor_submit -i request_cpus=8 request_gpus=1 -requirements="(CUDADeviceName!='Tesla K40m')"


condor_submit job.sub

condor_status --compact -af:h Machine NumDynamicSlots TotalCpus TotalGpus Cpus Gpus  State CUDADeviceName Memory

kill job: condor_rm <job_id>
condor_rm miranda9

Monitoring jobs
* condor_q: job status.
    * condor_q -nobatch: print individual job instead of grouping them together.
    * condor_q -nobatch -all: print jobs for all users.
* condor_status: machines' and individual job slots' running status and stuff
    * condor_status --compact: status for machines only
    * condor_status -af:h <fields>: Print specific fields. Useful fields include: Machine NumDynamicSlots TotalCpus TotalGpus TotalMemory Cpus Gpus Memory LoadAvg State CUDADeviceName RemoteOwner SlotWeight
    * condor_status --long: print a very long list of all ClassAd (i.e. properties) for everything. Specify which machine / job slot you want by condor_status --long <machine>.cs.illinois.edu.
* condor_userprio: users' resource usage
    * condor_userprio -all: full table
    * condor_userprio -getreslist <netID>@illinois.edu -all: for one user

For live resources score board: http://vision-sched.cs.illinois.edu:8765/.
Let us know if someone is constantly highlighted, or if the webpage is down.

----
intel

install conda in intel cluster:
export PATH="/export/software/anaconda3/bin:$PATH"

ssh -i ~/.ssh/intel_id_rsa miranda9@ssh-iam.intel-research.net

qsub <job-script>
qsub -lselect=1:ncpus=112 <job-script>

qsub -I
qsub -I -lselect=1:ncpus=112

----
HAL
support: help+isl@ncsa.illinois.edu

v100: CNN: 1.542 TransformerL 1.416

ssh miranda9@hal.ncsa.illinois.edu

swrun -p gpux1
srun --partition=debug --pty --nodes=1 \
     --ntasks-per-node=16 --cores-per-socket=4 \
     --threads-per-core=4 --sockets-per-node=1 \
     --mem-per-cpu=1200 --gres=gpu:v100:1 \
     --time 01:30:00 --wait=0 \
     --export=ALL /bin/bash

TODO: swbatch run_script.swb

see gpus in hal:
swqueue

using slurm in HAL (use to check partition): https://wiki.ncsa.illinois.edu/display/ISL20/Job+management+with+SLURM

#!/home/miranda9/.conda/envs/automl/bin/python3.7
#SBATCH --job-name="miranda9job"
#SBATCH --output="demo.%j.%N.out"
#SBATCH --error="demo.%j.%N.err"
#SBATCH --partition=debug
#SBATCH --time=4:00:00
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=16
#SBATCH --sockets-per-node=1
#SBATCH --cores-per-socket=4
#SBATCH --threads-per-core=4
#SBATCH --mem-per-cpu=1200
#SBATCH --export=ALL
#SBATCH --gres=gpu:v100:1

#!/home/miranda9/.conda/envs/automl/bin/python3.7
#SBATCH --job-name="miranda9job"
#SBATCH --output="demo.%j.%N.out"
#SBATCH --error="demo.%j.%N.err"
#SBATCH --partition=gpu
#SBATCH --time=4:00:00
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=16
#SBATCH --sockets-per-node=1
#SBATCH --cores-per-socket=4
#SBATCH --threads-per-core=4
#SBATCH --mem-per-cpu=1200
#SBATCH --export=ALL
#SBATCH --gres=gpu:v100:1


hal slurm job management: https://wiki.ncsa.illinois.edu/display/ISL20/Job+management+with+SLURM
hal pytorch insalling: https://wiki.ncsa.illinois.edu/display/ISL20/Frequently+Asked+Questions#FrequentlyAskedQuestions-IwanttoinstallTensorflow/PyTorch/CaffebutIcan'tinstalloneofitsdependencies
wmlce: https://wiki.ncsa.illinois.edu/display/ISL20/Installing+Python+Packages

using conda develop in HAL (clone their repo then add stuff to it): https://wiki.ncsa.illinois.edu/display/ISL20/Installing+Python+Packages
pytorch installation wmlce: https://wiki.ncsa.illinois.edu/pages/viewpage.action?pageId=82510352

module load wmlce/1.7.0-py3.7
module load wmlce/1.7.0-py3.7

create copy of wmlce env that HAL has
conda create --name=automl-meta-learning_wmlce-v1.7.0-py3.7 --clone=wmlce-v1.7.0-py3.7
conda activate automl-meta-learning_wmlce-v1.7.0-py3.6
conda remove --name automl-meta-learning_wmlce-v1.7.0-py3.7 --all

prepend the 1.7.0 code for wmlce
conda config --prepend channels \
https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/#/

create my own env
conda create -n automl-meta-learning python=3.7
conda activate automl-meta-learning

# conda install pytorch powerai-release=1.7.0
# conda install torchvision powerai-release=0.4.2
install the most recent powerai wmlce
conda config --prepend channels https://public.dhe.ibm.com/ibmdl/export/pub/software/server/ibm-ai/conda/
conda create -n my_new_env python=3.7 powerai=1.7.0
conda activate my_new_env

pip install torchmeta==1.3.1
pip install --no-deps torchmeta==1.3.1

conda create -n dawei python=3.7

https://github.com/h5py/h5py/issues/1678
https://github.com/IBM/powerai/issues/270
https://github.com/IBM/powerai/issues/269
https://stackoverflow.com/questions/64049603/how-does-one-install-torchmeta-for-a-ppc64le-architecture-in-pytorch
https://pypi.org/project/torchmeta/1.3.1/#files


from setuptools import setup, find_packages
from os import path
import sys

from io import open

extras = {
    'tcga': ['pandas~=0.24.0', 'academictorrents~=2.1.0', 'six~=1.11.0'],
}

here = path.abspath(path.dirname(__file__))

sys.path.insert(0, path.join(here, 'torchmeta'))
from version import VERSION

# Get the long description from the README file
with open(path.join(here, 'README.md'), encoding='utf-8') as f:
    long_description = f.read()

setup(
    name='torchmeta',
    version=VERSION,
    description='Dataloaders for meta-learning in Pytorch',
    long_description=long_description,
    long_description_content_type='text/markdown',
    license='MIT',
    author='Tristan Deleu',
    author_email='tristan.deleu@gmail.com',
    url='https://github.com/tristandeleu/pytorch-meta',
    keywords=['meta-learning', 'pytorch', 'few-shot', 'few-shot learning'],
    packages=find_packages(exclude=['data', 'contrib', 'docs', 'tests', 'examples']),
    install_requires=[
        'torch>=1.3.0,<1.5.0',
        'torchvision>=0.4.0,<0.6.0',
        'numpy>=1.14.0',
        'Pillow>=5.0.0,<7.0.0',
        'h5py~=2.9.0',
        'tqdm>=4.0.0',
        'requests' # Required by Torchvision
    ],
    extras_require=extras,
    package_data={'torchmeta': ['torchmeta/datasets/assets/*']},
    include_package_data=True,
    classifiers=[
        'Development Status :: 5 - Production/Stable',
        'Topic :: Scientific/Engineering :: Artificial Intelligence',
        'Intended Audience :: Science/Research',
        'Programming Language :: Python :: 3',
        'Programming Language :: Python :: 3.5',
        'Programming Language :: Python :: 3.6',
        'Programming Language :: Python :: 3.7',
        'License :: OSI Approved :: MIT License',
    ],
)

https://stackoverflow.com/questions/53152047/python-package-not-found-although-it-is-installed
https://stackoverflow.com/questions/39811929/package-installed-by-conda-python-cannot-find-it
https://stackoverflow.com/questions/31003994/anaconda-site-packages
https://docs.conda.io/projects/conda/en/latest/commands/list.html

----

RTX 3080: CNN: 1.4 Transformer: 1.208
RTX 3090: CNN: 1.58 Transformer: 1.5


